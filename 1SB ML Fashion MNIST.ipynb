{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning imports\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier, cv\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "\n",
    "# display setup\n",
    "plt.style.use('seaborn') # for plots\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preface\n",
    "* Fashion-MNIST is a dataset containing 70,000 samples, 60,000 for the training set and 10,000 for the test set.\n",
    "* Each sample is a 28x28 (784 pixels) grayscale image of a certain fashion item.\n",
    "* The data contains a column with 10 labels, making this a **multiclass classification** problem.\n",
    "In other words, this is a **supervised learning** task.\n",
    "* The model will be trained using all available data and run without learning anymore. This method is named **offline/batch learning**.\n",
    "* Main objective: Find the best algorithm and model parameters that classify the unused images correctly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Getting the Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read the csv file\n",
    "train_set = pd.read_csv(r\"FMNIST/fashion-mnist_train.csv\")\n",
    "test_set = pd.read_csv(r\"FMNIST/fashion-mnist_test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# display the first 5 rows for a quick look\n",
    "train_set.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# display the last 5 rows for a quick look\n",
    "train_set.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DataFrame shape (rows, columns)\n",
    "print(\"Training Set:\", train_set.shape)\n",
    "print(\"Test Set:\", test_set.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# description of data\n",
    "train_set.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# summary of the numerical attributes\n",
    "# null values are ignored\n",
    "train_set.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# maximum pixel value\n",
    "train_set.describe().loc['max'].max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# minimum pixel value\n",
    "train_set.describe().loc['min'].max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ### Features in the DataFrame:\n",
    "> There are 785 columns, one for the labels and 784 for the pixels (one for each pixel).\n",
    ">> Labels:\n",
    "> - 0 = T-shirt/top\n",
    "> - 1 = Trouser\n",
    "> - 2 = Pullover\n",
    "> - 3 = Dress\n",
    "> - 4 = Coat\n",
    "> - 5 = Sandal\n",
    "> - 6 = Shirt\n",
    "> - 7 = Sneaker\n",
    "> - 8 = Bag\n",
    "> - 9 = Ankle boot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "# number of instances for each category\n",
    "train_set[\"label\"].value_counts().sort_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Initial observations:\n",
    ">> 1. Each category has an equal amount of samples in the training set.\n",
    "2. Classes and pixel values are integers.\n",
    "3. The pixel range is [0, 255]. Some feature columns have a smaller maximum value or a\n",
    "greater minimum value. This means that the range is reduced for all training instances in\n",
    "that specific feature, in this case being a pixel value."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Understanding and Visualizing the Data\n",
    "> ##### *The motivation for this section is to gain more insights.*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data was split in advance and the images are already the same size.\n",
    "Let's create a copy of the data to prevent accidentally harming the training set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# deep copy of the training set\n",
    "fmnist = train_set.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DataFrame shape (rows, columns)\n",
    "# understand the amount of data we are working with\n",
    "fmnist.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "np.isnan(fmnist.values).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> #### Observations:\n",
    ">> * There are no missing values in the training set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ### Exploring Colors of Sample Image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sample image\n",
    "some_sample = fmnist.drop('label', axis=1).iloc[0] # get sample\n",
    "some_sample = np.array(some_sample) # convert to array\n",
    "some_sample_img = some_sample.reshape(28,28) # reshape array\n",
    "\n",
    "# convert sample image from grayscale to black and white\n",
    "# in the fashion mnist dataset white pixels are 0 and black pixels are 255\n",
    "# the images are grayscale, so values (0,255) are different intensities of gray\n",
    "some_sample_bin = some_sample.copy() # deep copy of the sample image\n",
    "some_sample_bin[some_sample_bin>0] = 1 # convert gray intensities to black\n",
    "some_sample_bin_img = some_sample_bin.reshape(28,28) # reshape array\n",
    "\n",
    "fig, dx = plt.subplots(2,2, figsize=(12, 7))\n",
    "\n",
    "# plot grayscale sample image and pixel value occurrences\n",
    "dx[0,0].imshow(some_sample_img)\n",
    "dx[0,0].axis('off')\n",
    "dx[0,0].set_title(\"Original Grayscale Sample\", size= 15)\n",
    "dx[0,1].hist(some_sample, bins=50)\n",
    "dx[0,1].set_title(\"Grayscale Sample Pixel Value Occurrences\", size= 15)\n",
    "dx[0,1].set_xlabel(\"Pixel Value\")\n",
    "dx[0,1].set_ylabel(\"Count\")\n",
    "# plot black and white sample image and pixel value occurrences\n",
    "dx[1,0].imshow(some_sample_bin_img)\n",
    "dx[1,0].axis('off')\n",
    "dx[1,0].set_title(\"Black and White Sample\", size= 15)\n",
    "dx[1,1].hist(some_sample_bin, bins=50)\n",
    "dx[1,1].set_title(\"Black and White Sample Pixel Value Occurrences\", size= 15)\n",
    "dx[1,1].set_xticks([0,1])\n",
    "dx[1,1].set_xlabel(\"Pixel Value\")\n",
    "dx[1,1].set_ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> #### Observations:\n",
    ">> * The most common pixel value in the original grayscale sample is white (0) and in the binary\n",
    "> sample is black (1).\n",
    "* Aside from a few pixels that are detached from the clothing, the item resembles the original grayscale shape.\n",
    "* Transforming the data from grayscale to black and white should be further evaluated during model training.\n",
    "There is a possibly it could improve the result."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ### Class Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot image for each category\n",
    "\n",
    "# use of a dictionary to easily add subplot titles\n",
    "label_dict = {0:\"0 = T-shirt/top\", 1:\"1 = Trouser\", 2:\"2 = Pullover\", 3:\"3 = Dress\", 4:\"4 = Coat\",\n",
    "              5:\"5 = Sandal\", 6:\"6 = Shirt\", 7:\"7 = Sneaker\", 8:\"8 = Bag\", 9:\"9 = Ankle boot\"}\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "rows = 2\n",
    "columns = 5\n",
    "# use groupby to locate an instance for each label\n",
    "label_groups = fmnist.groupby('label')\n",
    "# add image in each iteration\n",
    "for i in range(rows*columns):\n",
    "    curr = label_groups.get_group(i)[:1] # get group\n",
    "    curr_img = curr.drop('label', axis = 1).to_numpy().reshape(28,28) # convert to reshaped array\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.imshow(curr_img)\n",
    "    plt.axis('off') # remove grid\n",
    "    plt.title(label_dict[i]) # use dictionary to add subplot title\n",
    "\n",
    "fig.suptitle(\"Fashion-MNIST Samples\", size=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot pixel value occurrences for each class\n",
    "\n",
    "fig, dx = plt.subplots(2,5, figsize=(12, 7), sharey='all')\n",
    "i = 0 # current group label\n",
    "mean_values = []\n",
    "plt.setp(dx, xticks=np.arange(0, 256, step=85)) # set x axis values\n",
    "\n",
    "for row in range(2):\n",
    "    for col in range(5):\n",
    "        pixels = np.array(label_groups.get_group(i).drop(['label'], axis=1)) # get group and convert to array\n",
    "        mean_values.append(pixels.mean()) # calculate mean pixel value and add to list (for next plot)\n",
    "        dx[row,col].hist(pixels.reshape(-1)) # add histogram in each iteration, -1 reshapes to length of array\n",
    "        dx[row,col].set_title(label_dict[i], size=15) # use dictionary to add subplot title\n",
    "        i = i + 1 # next group\n",
    "\n",
    "fig.suptitle(\"Pixel Occurrences per Class\", size=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot mean values calculated in previous cell\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(x=np.arange(10), y=mean_values) # x axis for classes, y axis for mean values\n",
    "plt.xticks(np.arange(10), labels=label_dict.values()) # use dictionary to set x axis values\n",
    "plt.xlabel(\"Class\", size=15)\n",
    "plt.ylabel(\"Mean\", size=15)\n",
    "plt.title(\"Pixel Occurrences per Class Mean\", size=30)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> #### Observations:\n",
    ">> * All classes have a majority of white pixel values (0), with the remaining scattered in the rest of the range.\n",
    "* Aside from the white pixel value, quite a few of the histograms displaying pixel occurrences per class look like\n",
    "they have a somewhat normal distribution. They are tail-heavy, extending farther to the left of the\n",
    "median.\n",
    "* Any shoe type (classes 5, 7, 9) have the most white pixels, with sandal (class 5) containing the most.\n",
    "This is emphasized most in the pixel occurrences mean plot.\n",
    "* Coats (class 4) and pullovers (class 2) have the highest pixel mean. When looking at the sample\n",
    "images per class it is noticeable that they spread across most of the diagram.\n",
    "* The t-shirt/top (class 0) and shirt (class 6) have extremely similar pixel occurrences.\n",
    "Had the class labels been removed, the graphs would be indistinguishable. It is likely that\n",
    "the models will make mistakes when predicting instances from these two classes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ### Analyze and Compare Sample Images of T-shirt/top and Shirt Classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# t-shirt/top sample image (class 0)\n",
    "top = label_groups.get_group(0).drop('label', axis=1).iloc[0] # get t-shirt/top sample\n",
    "top = np.array(top) # convert to array\n",
    "top_img = top.reshape(28,28) # reshape array\n",
    "\n",
    "# convert t-shirt/top sample image from grayscale to black and white\n",
    "top_bin = top.copy() # deep copy of the t-shirt/top sample image\n",
    "top_bin[top_bin>0] = 1 # convert gray intensities to black\n",
    "top_bin_img = top_bin.reshape(28,28) # reshape array\n",
    "\n",
    "# shirt sample image (class 6)\n",
    "shirt = label_groups.get_group(6).drop('label', axis=1).iloc[0] # get t-shirt/top sample\n",
    "shirt = np.array(shirt) # convert to array\n",
    "shirt_img = shirt.reshape(28,28) # reshape array\n",
    "\n",
    "# convert shirt sample image from grayscale to black and white\n",
    "shirt_bin = shirt.copy() # deep copy of the shirt sample image\n",
    "shirt_bin[shirt_bin>0] = 1 # convert gray intensities to black\n",
    "shirt_bin_img = shirt_bin.reshape(28,28) # reshape array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, dx = plt.subplots(4,2, figsize=(10, 10))\n",
    "\n",
    "# plot grayscale t-shirt/top sample image and pixel value occurrences\n",
    "dx[0,0].imshow(top_img)\n",
    "dx[0,0].axis('off')\n",
    "dx[0,0].set_title(\"Grayscale T-shirt/top\", size= 15)\n",
    "dx[0,1].hist(top)\n",
    "dx[0,1].set_title(\"Grayscale T-shirt/top Pixel Value Occurrences\", size= 15)\n",
    "dx[0,1].set_xlabel(\"Pixel Value\")\n",
    "dx[0,1].set_ylabel(\"Count\")\n",
    "# plot black and white t-shirt/top sample image and pixel value occurrences\n",
    "dx[1,0].imshow(top_bin_img)\n",
    "dx[1,0].axis('off')\n",
    "dx[1,0].set_title(\"Black and White T-shirt/top\", size= 15)\n",
    "dx[1,1].hist(top_bin)\n",
    "dx[1,1].set_title(\"Black and White T-shirt/top Pixel Value Occurrences\", size= 15)\n",
    "dx[1,1].set_xticks([0,1])\n",
    "dx[1,1].set_xlabel(\"Pixel Value\")\n",
    "dx[1,1].set_ylabel(\"Count\")\n",
    "\n",
    "# plot grayscale shirt sample image and pixel value occurrences\n",
    "dx[2,0].imshow(shirt_img)\n",
    "dx[2,0].axis('off')\n",
    "dx[2,0].set_title(\"Grayscale Shirt\", size= 15)\n",
    "dx[2,1].hist(shirt)\n",
    "dx[2,1].set_title(\"Grayscale Shirt Pixel Value Occurrences\", size= 15)\n",
    "dx[2,1].set_xlabel(\"Pixel Value\")\n",
    "dx[2,1].set_ylabel(\"Count\")\n",
    "# plot black and white shirt sample image and pixel value occurrences\n",
    "dx[3,0].imshow(shirt_bin_img)\n",
    "dx[3,0].axis('off')\n",
    "dx[3,0].set_title(\"Black and White Shirt\", size= 15)\n",
    "dx[3,1].hist(shirt_bin)\n",
    "dx[3,1].set_title(\"Black and White Shirt Pixel Value Occurrences\", size= 15)\n",
    "dx[3,1].set_xticks([0,1])\n",
    "dx[3,1].set_xlabel(\"Pixel Value\")\n",
    "dx[3,1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> #### Observations:\n",
    ">> * The main difference between the classes are the pixels representing the sleeves.\n",
    "> The t-shirt/top has short sleeves and the shirt has long sleeves.\n",
    "* Converting the images to binary shows where the mix-up between the classes might be.\n",
    "The t-shirt has gray pixels that aren't seen in the grayscale image, but stand out in the\n",
    "black and white image. The unseen gray pixels appear where the long sleeves would be\n",
    "had this been a shirt.\n",
    "* The pixel value occurrences are similar when comparing the black and white images and are\n",
    "spread out differently in the grayscale images."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Data Cleaning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clean copy of the training set\n",
    "df = train_set.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# separate features from target values\n",
    "\n",
    "# drop- creates a copy without changing the training set\n",
    "X_train = df.drop('label', axis=1)\n",
    "\n",
    "# create a deep copy of the target values\n",
    "y_train = df['label'].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ### Custom Transformer:\n",
    "> In section 2, I evaluated samples in grayscale and in black and white.\n",
    "> I assumed that converting images to black and white could improve the ML algorithms.\n",
    ">\n",
    "> The following custom transformer automates this process on the entire dataset:\n",
    ">\n",
    ">> The ColorConverter transformer contains the hyperparameter \"is_binary\". It is\n",
    "> set by default to 'False', meaning the samples remain in the original grayscale format.\n",
    "> However, the hyperparameter can be set to 'True' which will convert the images to black\n",
    "> and white.\n",
    ">>\n",
    ">> Adding this transformer will allow to easily switch between the two options during\n",
    "> model training, and determine which one is better."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# custom transformer for converting images to black and white\n",
    "# default is set to leave as original grayscale images\n",
    "# when is_binary hyperparameter is set to True data is converted to binary\n",
    "\n",
    "# BaseEstimator for enabling hyperparameters\n",
    "# TransformerMixin adds fit_transform method\n",
    "class ColorConverter(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, is_binary = False):\n",
    "        self.is_binary = is_binary\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.is_binary:\n",
    "            X_binary = X.copy()\n",
    "            X_binary[X_binary>0] = 1\n",
    "            return X_binary\n",
    "        else:\n",
    "            return X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "clr_gray = ColorConverter()\n",
    "clr_binary = ColorConverter(is_binary = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "X_train_gray = clr_gray.transform(X_train.values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "X_train_bin = clr_binary.transform(X_train.values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "plt.imshow(X_train_bin[0].reshape(28,28))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "plt.imshow(X_train_gray[0].reshape(28,28))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ### Feature Scaling\n",
    "\n",
    "Although the pixel values are in a known range [0,255], scaling the data can make a crucial difference\n",
    "(especially if the learning algorithm relies on calculating distances).\n",
    "\n",
    "> Why is this important?\n",
    "* Models can't differentiate feature importance the same way humans can.\n",
    "A training algorithm may assume that a feature containing large numbers is more important than features\n",
    "with smaller numbers- which might not be the case.\n",
    "* Some algorithms converge much faster when features are scaled (i.e. Gradient Descent).\n",
    "* There are ML algorithms that make assumptions on the data (i.e. PCA assumes the data is centered around\n",
    "the origin).\n",
    ">\n",
    "\n",
    "Chosen feature scale:\n",
    "\n",
    "Standardizing centers the data so that it has a zero mean and a standard deviation of 1, under the assumption\n",
    "that the data is normally distributed.\n",
    "\n",
    "* The distribution is relatively normal (aside from the white pixels which is highest in all classes).\n",
    "* Using PCA could be useful since the dataset has a large amount of features. As previously stated,\n",
    "PCA assumes the data has zero mean.\n",
    "\n",
    "Therefore, standard scaling is the ideal option."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create transformation pipeline\n",
    "\n",
    "# How to change ColorConverter is_binary hyperparameter:\n",
    "# full_pipeline['clr_convert'].__setattr__('is_binary', True)\n",
    "\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('clr_convert', ColorConverter()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# transform training data using pipeline\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "\n",
    "# transform training data without fit for testing\n",
    "X_tr_testing = full_pipeline.transform(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "full_pipeline['clr_convert'].__setattr__('is_binary', True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "full_pipeline.steps[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# transform training data using pipeline\n",
    "X_train_prepared2 = full_pipeline.fit_transform(X_train)\n",
    "\n",
    "# transform training data without fit for testing\n",
    "X_tr_testing2 = full_pipeline.transform(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Training and Evaluating Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> The number of instances for each class in the training set are equal which makes this\n",
    "> a balanced classification task.\n",
    ">\n",
    "> Chosen evaluation metric:\n",
    ">\n",
    "> Accuracy works well with balanced classification tasks. It is also the most intuitive\n",
    "> metric and is especially easier to understand when dealing with multiclass classification."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# function for evaluating cross validation scores and for easy model comparison\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard Deviation:\", scores.std())\n",
    "\n",
    "# function prints accuracy and errors\n",
    "def display_evaluation(actual, pred):\n",
    "    print(\"Accuracy:\\n\", metrics.accuracy_score(actual, pred), \"\\n\")\n",
    "    print(\"Display Errors in Confusion Matrix:\\n\")\n",
    "    conf_mx = metrics.confusion_matrix(actual, pred)\n",
    "    row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "    norm_conf_mx = conf_mx / row_sums\n",
    "    np.fill_diagonal(norm_conf_mx, 0)\n",
    "    plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Shortlist Promising Models:\n",
    "> Trying many models quickly and selecting the ones that show promising results.\n",
    ">\n",
    ">> How I plan to do this:\n",
    "1. Train a baseline model and evaluate sample predictions.\n",
    "**Continue to step 2 if the sample predictions were mostly correct.**\n",
    "2. Use cross-validation and evaluate scores.\n",
    "3. If the model has a significant hyperparameters, try changing it. Use cross-validation to\n",
    "compare the results to step 2.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# a few instances from the training data for testing\n",
    "some_data = X_train.iloc[:10]\n",
    "some_labels = y_train.iloc[:10]\n",
    "some_data_prepared = full_pipeline.transform(some_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "log_reg = LogisticRegression(random_state=42, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_reg.fit(X_train_prepared, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Predictions:\", log_reg.predict(some_data_prepared))\n",
    "print(\"Labels:\", list(some_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_reg_scores = cross_val_score(log_reg, X_train_prepared, y_train, scoring='accuracy', cv=6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_scores(log_reg_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. KNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# using default weights (uniform)\n",
    "# using default n_neighbors (n = 5)\n",
    "knn_clf = KNeighborsClassifier(n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_clf.fit(X_train_prepared, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Predictions:\", knn_clf.predict(some_data_prepared))\n",
    "print(\"Labels:\", list(some_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_scores = cross_val_score(knn_clf, X_train_prepared, y_train, scoring='accuracy', cv=6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_scores(knn_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_clf2 =KNeighborsClassifier(n_jobs=-1, weights='distance')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_clf2.fit(X_train_prepared, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Predictions:\", knn_clf2.predict(some_data_prepared))\n",
    "print(\"Labels:\", list(some_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_scores2 = cross_val_score(knn_clf2, X_train_prepared, y_train, scoring='accuracy', cv=6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_scores(knn_scores2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Decision Tree Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_clf.fit(X_train_prepared, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Predictions:\", tree_clf.predict(some_data_prepared))\n",
    "print(\"Labels:\", list(some_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_scores = cross_val_score(tree_clf, X_train_prepared, y_train, scoring='accuracy', cv=6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_scores(tree_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=42, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf_clf.fit(X_train_prepared, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Predictions:\", rf_clf.predict(some_data_prepared))\n",
    "print(\"Labels:\", list(some_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf_scores = cross_val_score(rf_clf, X_train_prepared, y_train, scoring='accuracy', cv=6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_scores(rf_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ### Feature Importance:\n",
    "> Random Forests automatically computes the importance of each feature after training\n",
    "> and even scales them, making the total sum equal to 1.\n",
    "> This provides a quick insight to which features really matter."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot random forest classifier feature importance\n",
    "img = rf_clf.feature_importances_.reshape(28,28)\n",
    "plt.imshow(img, cmap= plt.cm.hot, interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "cbar = plt.colorbar(ticks=[rf_clf.feature_importances_.min(), rf_clf.feature_importances_.max()])\n",
    "cbar.ax.set_yticklabels(['Not important', 'Very Important'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ### Observations:\n",
    "* The corners and left and right edges are least important. Dropping them should be considered."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "feat = pd.Series(rf_clf.feature_importances_, index=X_train.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "feat.nsmallest(40)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "feat = rf_clf.feature_importances_.reshape(28,28)\n",
    "feat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "thresh = (feat[0,0] + feat[0, -1] + feat[-1, 0] + feat[-1, -1]) / 4\n",
    "thresh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5. Extra Trees Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ex_tree = ExtraTreesClassifier(random_state=42, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ex_tree.fit(X_train_prepared, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Predictions:\", rf_clf.predict(some_data_prepared))\n",
    "print(\"Labels:\", list(some_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ex_tree_scores = cross_val_score(ex_tree, X_train_prepared, y_train, scoring='accuracy', cv=6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_scores(ex_tree_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6. AdaBoost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "                             algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ada_clf.fit(X_train_prepared, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Predictions:\", ada_clf.predict(some_data_prepared))\n",
    "print(\"Labels:\", list(some_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 7. XGBoost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Early stopping with XGBoost requires a validation set. In order to implement this,\n",
    "I will create a validation set from the training data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_set, X_val, y_set, y_val = train_test_split(X_train, y_train, test_size=10000, random_state=42,\n",
    "                                              stratify=y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_set.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_set_prepared = full_pipeline.fit_transform(X_set, y_set)\n",
    "X_val_prepared = full_pipeline.transform(X_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(random_state=42, n_jobs=-1, use_label_encoder=False, eval_metric='merror',\n",
    "                        objective='multi:softmax', num_class=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgb_clf.fit(X_set_prepared, y_set, eval_set=[(X_val_prepared, y_val)], early_stopping_rounds=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Predictions:\", xgb_clf.predict(some_data_prepared))\n",
    "print(\"Labels:\", list(some_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "xgb_scores = cross_val_score(xgb_clf, X_train_prepared, y_train, scoring='accuracy', cv=6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "display_scores(xgb_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* early_stopping_rounds=2, 53 rounds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> #### Round 2:\n",
    "> Evaluating the models that made few to no prediction errors using cross validation.\n",
    "> Additionally, if the models have"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "xgb_clf = XGBClassifier(random_state=42, n_jobs=-1, use_label_encoder=False, eval_metric='merror',\n",
    "                        objective='multi:softmax', num_class=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "xgb_clf.fit(X_train_prepared, y_train, early_stopping_rounds=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "X_reduced = pca.fit_transform(X_set_prepared)\n",
    "X_reduced_test = pca.transform(X_val_prepared)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "rf_clf2 = RandomForestClassifier(random_state=42, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "rf_scores2 = cross_val_score(rf_clf2, X_reduced, y_train, scoring='accuracy', cv=6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "display_scores(rf_scores2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(random_state=42, n_jobs=-1, use_label_encoder=False, eval_metric='merror',\n",
    "                        objective='multi:softmax', num_class=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgb_clf.fit(X_reduced, y_set, eval_set=[(X_reduced_test, y_val)], early_stopping_rounds=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "some_data_prepared_reduced = pca.transform(some_data_prepared)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Predictions:\", xgb_clf.predict(some_data_prepared_reduced))\n",
    "print(\"Labels:\", list(some_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = xgb_clf.predict(X_reduced_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_evaluation(y_val, pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> #### Resources:\n",
    "> 1. Fashion MNIST Dataset <a href=\"https://www.kaggle.com/zalando-research/fashionmnist\"\n",
    "> title=\"Kaggle\">link</a>\n",
    "> 2. Feature Scaling Article <a href=\"https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35\"\n",
    "> title=\"towardsdatascience\">link</a>\n",
    "> 3. PCA Article <a href=\"https://towardsdatascience.com/pca-is-not-feature-selection-3344fb764ae6\"\n",
    "> title=\"towardsdatascience\">link</a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-bcecade4",
   "language": "python",
   "display_name": "PyCharm (1SB-Final-Project)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}